{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import gc\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, save_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data / agumment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading our train data\n",
    "train_df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting top 10 whales that are not new_whale, setting to new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_23a388d    73\n",
      "w_9b5109b    65\n",
      "w_9c506f6    62\n",
      "w_0369a5c    61\n",
      "w_700ebb4    57\n",
      "w_3de579a    54\n",
      "w_564a34b    51\n",
      "w_fd3e556    50\n",
      "w_88e4537    49\n",
      "w_2b069ba    48\n",
      "Name: Id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>004e8ad5b.jpg</td>\n",
       "      <td>w_3de579a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00570db6b.jpg</td>\n",
       "      <td>w_9c506f6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image         Id\n",
       "26  004e8ad5b.jpg  w_3de579a\n",
       "32  00570db6b.jpg  w_9c506f6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collecting whales that are not new_whale\n",
    "whale_df = train_df[train_df.Id != 'new_whale']\n",
    "# getting top ten whales\n",
    "top_ten = whale_df[\"Id\"].value_counts().head(10)\n",
    "print(top_ten)\n",
    "\n",
    "# making a new df with top 10\n",
    "columns = ['Image', 'Id']\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(len(train_df['Id'])):\n",
    "    if train_df['Id'].loc[i] in top_ten:\n",
    "        new_df.loc[i] = (train_df['Image'].loc[i], train_df['Id'].loc[i])\n",
    "new_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  456\n",
      "Shape of X_test:  114\n",
      "Shape of y_train:  456\n",
      "Shape of y_test:  114\n",
      "25035    fc5c296f8.jpg\n",
      "19678    c669a3706.jpg\n",
      "Name: Image, dtype: object\n",
      "25035    w_0369a5c\n",
      "19678    w_700ebb4\n",
      "Name: Id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_df['Image'], new_df['Id'], test_size=0.20)\n",
    "\n",
    "print(\"Shape of X_train: \", X_train.shape[0])\n",
    "print(\"Shape of X_test: \", X_test.shape[0])\n",
    "print(\"Shape of y_train: \", y_train.shape[0])\n",
    "print(\"Shape of y_test: \", y_test.shape[0])\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image data generator ( agumentation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.15,\n",
    "                        zoom_range=0.1, channel_shift_range=10,\n",
    "                        horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing every image from data set and resizing / agumentating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def processImages(data, dataset, imageCount = 0):\n",
    "    i = 0\n",
    "    for fig in data['Image']:\n",
    "        img = image.load_img(\"./input/\"+dataset+\"/\"+fig, target_size=(100, 100, 3))\n",
    "        img_arr = image.img_to_array(img)\n",
    "        image.save_img('./processed/100_100_0_'+fig, img_arr)\n",
    "        temp_image = np.expand_dims(mpimg.imread('./processed/100_100_0_'+fig), 0)\n",
    "        aug_iter = gen.flow(temp_image)\n",
    "        aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(imageCount)]\n",
    "        for x in range(len(aug_images)):\n",
    "            image.save_img('./processed/100_100_'+str(x+1)+'_'+fig, aug_images[x])\n",
    "        if (i%100 == 0):\n",
    "            print(\"Processing image: \", i+1, \", \", fig)\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processImages(new_df, 'train', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to prep our images to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareImages(data, m, type_of_data, imageCount = 1):\n",
    "    \n",
    "    print(\"Preparing images\")\n",
    "    \n",
    "    if type_of_data == 'training':\n",
    "        X = np.zeros((m*imageCount, 100, 100, 3))\n",
    "        count = 0\n",
    "        for fig in data:\n",
    "            #load images into images of size 100x100x3\n",
    "            for i in range(imageCount):\n",
    "                img = image.load_img('./processed/100_100_' + str(i) + '_' + fig, target_size=(100, 100, 3))\n",
    "                x = image.img_to_array(img)\n",
    "                x = preprocess_input(x)\n",
    "                X[count] = x\n",
    "                count += 1\n",
    "                if (count%100 == 0):\n",
    "                    print(\"Processing image: \", count+1, \", \", fig)\n",
    "    elif type_of_data == 'testing':\n",
    "        X = np.zeros((m, 100, 100, 3))\n",
    "        count = 0\n",
    "        for fig in data:\n",
    "            img = image.load_img('./processed/100_100_0_' + fig, target_size=(100, 100, 3))\n",
    "            x = image.img_to_array(img)\n",
    "            x = preprocess_input(x)\n",
    "            X[count] = x\n",
    "            count += 1\n",
    "            if (count%50 == 0):\n",
    "                print(\"Processing image: \", count+1, \", \", fig)    \n",
    "    return X\n",
    "\n",
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  101 ,  e6bfde781.jpg\n",
      "Processing image:  201 ,  317a126f4.jpg\n",
      "Processing image:  301 ,  471e75940.jpg\n",
      "Processing image:  401 ,  1eef410a0.jpg\n",
      "Preparing images\n",
      "Processing image:  51 ,  eaa3332d8.jpg\n",
      "Processing image:  101 ,  a6c4cab26.jpg\n"
     ]
    }
   ],
   "source": [
    "X_train_processed = prepareImages(X_train, X_train.shape[0], 'training')\n",
    "X_test_processed = prepareImages(X_test, X_test.shape[0], 'testing')\n",
    "X_train_processed /= 255\n",
    "X_test_processed /= 255\n",
    "\n",
    "# X = prepareImages(new_df['Image'], new_df['Image'].shape[0], 'training')\n",
    "# X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Image count:  (456, 100, 100, 3)\n",
      "X_test Image count:  (114, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Image count: ', X_train_processed.shape)\n",
    "print('X_test Image count: ', X_test_processed.shape)\n",
    "# print('X_test Image count: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "imageCount = 1\n",
    "# Setting up our y.\n",
    "new_y_array = []\n",
    "for x in y_train:\n",
    "    for y in range(imageCount):\n",
    "        new_y_array.append(x)\n",
    "\n",
    "y_train_processed, label_encorder = prepare_labels(new_y_array)\n",
    "y_test_processed, label_encorder = prepare_labels(y_test)\n",
    "\n",
    "# y, label_encorder = prepare_labels(new_y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train processed shape:  (456, 10)\n",
      "Y test processed shape:  (114, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Y train processed shape: ', y_train_processed.shape)\n",
    "print('Y test processed shape: ', y_test_processed.shape)\n",
    "# print(\"Y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting and randominizing our data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p_n, X_test_p_n, y_train_p_n, y_test_p_n = train_test_split(X_train_processed, y_train_processed, random_state = 20, test_size=0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, (3, 3), strides=(1,1), activation='relu', input_shape = (100, 100, 3)))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), strides=(1,1), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 3), strides=(1,1), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(650, activation=\"relu\"))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 650)               8320650   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                6510      \n",
      "=================================================================\n",
      "Total params: 8,420,408\n",
      "Trainable params: 8,420,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a callback for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "456/456 [==============================] - 6s 12ms/step - loss: 2.4752 - acc: 0.1009: 6s - loss: 2.6241 - acc: 0.\n",
      "\n",
      "Testing loss: 2.29959287559777, acc: 0.13157894762984493\n",
      "\n",
      "Epoch 2/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 2.2903 - acc: 0.1360\n",
      "\n",
      "Testing loss: 2.294657853611729, acc: 0.1403508792843735\n",
      "\n",
      "Epoch 3/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 2.3028 - acc: 0.1250\n",
      "\n",
      "Testing loss: 2.2830817490293267, acc: 0.24561403613341481\n",
      "\n",
      "Epoch 4/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 2.2579 - acc: 0.1425\n",
      "\n",
      "Testing loss: 2.2345504593430903, acc: 0.21052631578947367\n",
      "\n",
      "Epoch 5/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 2.1771 - acc: 0.2083\n",
      "\n",
      "Testing loss: 2.1036037353047154, acc: 0.31578947472990604\n",
      "\n",
      "Epoch 6/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 2.0607 - acc: 0.2281\n",
      "\n",
      "Testing loss: 2.0027587957549513, acc: 0.38596491332639726\n",
      "\n",
      "Epoch 7/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.9816 - acc: 0.2829\n",
      "\n",
      "Testing loss: 1.9455660100568806, acc: 0.3333333338561811\n",
      "\n",
      "Epoch 8/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.8373 - acc: 0.3553\n",
      "\n",
      "Testing loss: 1.7633523606417472, acc: 0.43859649122807015\n",
      "\n",
      "Epoch 9/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.7519 - acc: 0.4079\n",
      "\n",
      "Testing loss: 1.7247696006507205, acc: 0.43859649122807015\n",
      "\n",
      "Epoch 10/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 1.6391 - acc: 0.4167\n",
      "\n",
      "Testing loss: 1.5950916378121627, acc: 0.5263157926107708\n",
      "\n",
      "Epoch 11/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.5256 - acc: 0.4605\n",
      "\n",
      "Testing loss: 1.608432976823104, acc: 0.4561403550599751\n",
      "\n",
      "Epoch 12/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.5045 - acc: 0.4978\n",
      "\n",
      "Testing loss: 1.5136467009259944, acc: 0.4736842094806203\n",
      "\n",
      "Epoch 13/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.4231 - acc: 0.4890\n",
      "\n",
      "Testing loss: 1.4668706509104945, acc: 0.5087719287788659\n",
      "\n",
      "Epoch 14/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.3142 - acc: 0.5461\n",
      "\n",
      "Testing loss: 1.401583050426684, acc: 0.5175438627862093\n",
      "\n",
      "Epoch 15/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.2385 - acc: 0.5548\n",
      "\n",
      "Testing loss: 1.3195532309381586, acc: 0.552631582084455\n",
      "\n",
      "Epoch 16/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.1585 - acc: 0.5877\n",
      "\n",
      "Testing loss: 1.277172699309232, acc: 0.5964912259787843\n",
      "\n",
      "Epoch 17/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 1.0400 - acc: 0.6557\n",
      "\n",
      "Testing loss: 1.1861828293716699, acc: 0.587719296154223\n",
      "\n",
      "Epoch 18/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 1.0679 - acc: 0.6382\n",
      "\n",
      "Testing loss: 1.2317410100970352, acc: 0.5789473715581392\n",
      "\n",
      "Epoch 19/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 0.9827 - acc: 0.6820\n",
      "\n",
      "Testing loss: 1.1689476402182328, acc: 0.6052631610318234\n",
      "\n",
      "Epoch 20/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.9252 - acc: 0.6974\n",
      "\n",
      "Testing loss: 1.1452842020151908, acc: 0.6228070154524686\n",
      "\n",
      "Epoch 21/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.8635 - acc: 0.7149\n",
      "\n",
      "Testing loss: 1.0840982784304702, acc: 0.5701754365051002\n",
      "\n",
      "Epoch 22/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.7870 - acc: 0.7281\n",
      "\n",
      "Testing loss: 1.081419545307494, acc: 0.6052631599861279\n",
      "\n",
      "Epoch 23/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.7256 - acc: 0.7544\n",
      "\n",
      "Testing loss: 1.133103569348653, acc: 0.63157894527703\n",
      "\n",
      "Epoch 24/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.7519 - acc: 0.7456\n",
      "\n",
      "Testing loss: 1.110429626807832, acc: 0.6491228049261528\n",
      "\n",
      "Epoch 25/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.6058 - acc: 0.7917\n",
      "\n",
      "Testing loss: 1.116296188873157, acc: 0.6140350856279072\n",
      "\n",
      "Epoch 26/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.5947 - acc: 0.8202\n",
      "\n",
      "Testing loss: 1.1121610821339123, acc: 0.6140350898106893\n",
      "\n",
      "Epoch 27/40\n",
      "456/456 [==============================] - 1s 1ms/step - loss: 0.5658 - acc: 0.7961\n",
      "\n",
      "Testing loss: 1.07164291227073, acc: 0.6052631610318234\n",
      "\n",
      "Epoch 28/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.5678 - acc: 0.7961\n",
      "\n",
      "Testing loss: 1.0722812037718923, acc: 0.6228070154524686\n",
      "\n",
      "Epoch 29/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.4436 - acc: 0.8596\n",
      "\n",
      "Testing loss: 1.1212047965903031, acc: 0.6403508751015914\n",
      "\n",
      "Epoch 30/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.5207 - acc: 0.8092\n",
      "\n",
      "Testing loss: 1.148453200072573, acc: 0.6315789494598121\n",
      "\n",
      "Epoch 31/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.3927 - acc: 0.8640\n",
      "\n",
      "Testing loss: 1.0594599163323117, acc: 0.6403508751015914\n",
      "\n",
      "Epoch 32/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.4087 - acc: 0.8531\n",
      "\n",
      "Testing loss: 1.0277242974231118, acc: 0.6929824582317419\n",
      "\n",
      "Epoch 33/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.4173 - acc: 0.8706\n",
      "\n",
      "Testing loss: 1.0189759511696665, acc: 0.7017543880563033\n",
      "\n",
      "Epoch 34/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.3917 - acc: 0.8684\n",
      "\n",
      "Testing loss: 1.0329752282092446, acc: 0.6842105294528761\n",
      "\n",
      "Epoch 35/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.3545 - acc: 0.8882\n",
      "\n",
      "Testing loss: 1.0831283320460403, acc: 0.640350880330069\n",
      "\n",
      "Epoch 36/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.3753 - acc: 0.8728\n",
      "\n",
      "Testing loss: 1.0964465339978535, acc: 0.6754385996283147\n",
      "\n",
      "Epoch 37/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.2870 - acc: 0.9123\n",
      "\n",
      "Testing loss: 1.1146738142297978, acc: 0.7017543880563033\n",
      "\n",
      "Epoch 38/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.2543 - acc: 0.9079\n",
      "\n",
      "Testing loss: 1.1140161585389523, acc: 0.675438594399837\n",
      "\n",
      "Epoch 39/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.2192 - acc: 0.9364\n",
      "\n",
      "Testing loss: 1.1845600395871883, acc: 0.675438594399837\n",
      "\n",
      "Epoch 40/40\n",
      "456/456 [==============================] - 1s 2ms/step - loss: 0.2150 - acc: 0.9276\n",
      "\n",
      "Testing loss: 1.1396003511914037, acc: 0.6929824540489599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_p_n, y_train_p_n, batch_size=64, epochs=40, callbacks=[TestCallback((X_test_processed, y_test_processed))], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 763us/step\n",
      "The accuracy is : 0.6929824540489599\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_processed, y_test_processed, verbose=1)\n",
    "print('The accuracy is :', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more agumented images to our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  101 ,  ed77166d6.jpg\n",
      "Processing image:  201 ,  fe7a2b654.jpg\n",
      "Processing image:  301 ,  614836cf8.jpg\n",
      "Processing image:  401 ,  511834bc3.jpg\n",
      "Processing image:  501 ,  c64cabd50.jpg\n",
      "Processing image:  601 ,  4b6831b73.jpg\n",
      "Processing image:  701 ,  e6bfde781.jpg\n",
      "Processing image:  801 ,  9e924e18d.jpg\n",
      "Processing image:  901 ,  680070ef1.jpg\n",
      "Processing image:  1001 ,  396b9f681.jpg\n",
      "Processing image:  1101 ,  81b79b1fd.jpg\n",
      "Processing image:  1201 ,  da3529684.jpg\n",
      "Processing image:  1301 ,  877e3feda.jpg\n",
      "Processing image:  1401 ,  317a126f4.jpg\n",
      "Processing image:  1501 ,  931a21ac9.jpg\n",
      "Processing image:  1601 ,  2d83b5312.jpg\n",
      "Processing image:  1701 ,  4b3abf879.jpg\n",
      "Processing image:  1801 ,  7fb338aa0.jpg\n",
      "Processing image:  1901 ,  bcd3b6249.jpg\n",
      "Processing image:  2001 ,  8cfcac09c.jpg\n",
      "Processing image:  2101 ,  471e75940.jpg\n",
      "Processing image:  2201 ,  83d05e445.jpg\n",
      "Processing image:  2301 ,  fddc28401.jpg\n",
      "Processing image:  2401 ,  cdb4eb77e.jpg\n",
      "Processing image:  2501 ,  0d3e8320a.jpg\n",
      "Processing image:  2601 ,  40057c4ee.jpg\n",
      "Processing image:  2701 ,  f004d6421.jpg\n",
      "Processing image:  2801 ,  1eef410a0.jpg\n",
      "Processing image:  2901 ,  bb2c265fa.jpg\n",
      "Processing image:  3001 ,  659087602.jpg\n",
      "Processing image:  3101 ,  40bb25e45.jpg\n",
      "Preparing images\n",
      "Processing image:  51 ,  eaa3332d8.jpg\n",
      "Processing image:  101 ,  a6c4cab26.jpg\n"
     ]
    }
   ],
   "source": [
    "X_train_processed = prepareImages(X_train, X_train.shape[0], 'training', 7)\n",
    "X_test_processed = prepareImages(X_test, X_test.shape[0], 'testing', 7)\n",
    "X_train_processed /= 255\n",
    "X_test_processed /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Image count:  (3192, 100, 100, 3)\n",
      "X_test Image count:  (114, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Image count: ', X_train_processed.shape)\n",
    "print('X_test Image count: ', X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\acons\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "imageCount = 7\n",
    "# Setting up our y.\n",
    "new_y_array = []\n",
    "for x in y_train:\n",
    "    for y in range(imageCount):\n",
    "        new_y_array.append(x)\n",
    "\n",
    "y_train_processed, label_encorder = prepare_labels(new_y_array)\n",
    "y_test_processed, label_encorder = prepare_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train processed shape:  (3192, 10)\n",
      "Y test processed shape:  (114, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Y train processed shape: ', y_train_processed.shape)\n",
    "print('Y test processed shape: ', y_test_processed.shape)\n",
    "# print(\"Y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p_n, X_test_p_n, y_train_p_n, y_test_p_n = train_test_split(X_train_processed, y_train_processed, test_size=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 650)               8320650   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                6510      \n",
      "=================================================================\n",
      "Total params: 8,420,408\n",
      "Trainable params: 8,420,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3192/3192 [==============================] - 6s 2ms/step - loss: 2.2190 - acc: 0.1839\n",
      "\n",
      "Testing loss: 2.002661290921663, acc: 0.27192982560709905\n",
      "\n",
      "Epoch 2/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 1.9059 - acc: 0.3139\n",
      "\n",
      "Testing loss: 1.7088563860508434, acc: 0.4736842147090979\n",
      "\n",
      "Epoch 3/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 1.6655 - acc: 0.3941\n",
      "\n",
      "Testing loss: 1.3932089429152639, acc: 0.5877192971999186\n",
      "\n",
      "Epoch 4/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 1.4240 - acc: 0.4809\n",
      "\n",
      "Testing loss: 1.272735361467328, acc: 0.5438596480771115\n",
      "\n",
      "Epoch 5/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 1.2253 - acc: 0.5498\n",
      "\n",
      "Testing loss: 1.0306818955822994, acc: 0.6491228049261528\n",
      "\n",
      "Epoch 6/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 1.0620 - acc: 0.6150\n",
      "\n",
      "Testing loss: 0.9175939110287449, acc: 0.7105263126523871\n",
      "\n",
      "Epoch 7/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.9191 - acc: 0.6689A: 4s - l - ETA: 1s - loss\n",
      "\n",
      "Testing loss: 0.8884822485739725, acc: 0.7543859670036718\n",
      "\n",
      "Epoch 8/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.7957 - acc: 0.7190\n",
      "\n",
      "Testing loss: 0.8050280412038168, acc: 0.7368421021260714\n",
      "\n",
      "Epoch 9/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.7079 - acc: 0.7459\n",
      "\n",
      "Testing loss: 0.8173583996923346, acc: 0.7368421073545489\n",
      "\n",
      "Epoch 10/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.6422 - acc: 0.7669\n",
      "\n",
      "Testing loss: 0.7389693856239319, acc: 0.780701756477356\n",
      "\n",
      "Epoch 11/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.5572 - acc: 0.8026\n",
      "\n",
      "Testing loss: 0.6938792655342504, acc: 0.780701756477356\n",
      "\n",
      "Epoch 12/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.5318 - acc: 0.8073A: 0s - loss: 0.5322 - acc\n",
      "\n",
      "Testing loss: 0.6939477042147988, acc: 0.815789474729906\n",
      "\n",
      "Epoch 13/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.4406 - acc: 0.8415\n",
      "\n",
      "Testing loss: 0.5883896643655342, acc: 0.824561405600163\n",
      "\n",
      "Epoch 14/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.4177 - acc: 0.8477A: 2s - lo\n",
      "\n",
      "Testing loss: 0.6244781686548602, acc: 0.8157894705471239\n",
      "\n",
      "Epoch 15/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.3969 - acc: 0.8634\n",
      "\n",
      "Testing loss: 0.584807224440993, acc: 0.8508771898453695\n",
      "\n",
      "Epoch 16/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.3444 - acc: 0.8819\n",
      "\n",
      "Testing loss: 0.6226066523476651, acc: 0.8596491186242354\n",
      "\n",
      "Epoch 17/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.3199 - acc: 0.8857A: 1s - loss: 0.3270 -\n",
      "\n",
      "Testing loss: 0.5748325168040761, acc: 0.8421052642035902\n",
      "\n",
      "Epoch 18/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.3056 - acc: 0.8988\n",
      "\n",
      "Testing loss: 0.6233250864765101, acc: 0.8245614003716853\n",
      "\n",
      "Epoch 19/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.2748 - acc: 0.9038\n",
      "\n",
      "Testing loss: 0.5916925501405147, acc: 0.8421052642035902\n",
      "\n",
      "Epoch 20/20\n",
      "3192/3192 [==============================] - 5s 1ms/step - loss: 0.2616 - acc: 0.9129\n",
      "\n",
      "Testing loss: 0.682184054140459, acc: 0.8333333301962468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_p_n, y_train_p_n, batch_size=64, epochs=20, callbacks=[TestCallback((X_test_processed, y_test_processed))], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 789us/step\n",
      "The accuracy is : 0.8333333301962468\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_processed, y_test_processed, verbose=1)\n",
    "print('The accuracy is :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
